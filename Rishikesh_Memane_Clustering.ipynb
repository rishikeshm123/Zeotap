{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load customer and transaction data\n",
    "customers_df = pd.read_csv('Customers.csv')\n",
    "transactions_df = pd.read_csv('Transactions.csv')\n",
    "\n",
    "# Merge customer and transaction data if needed (for example, based on CustomerID)\n",
    "merged_df = pd.merge(customers_df, transactions_df, on='CustomerID',how = \"inner\")\n",
    "\n",
    "# Ensure 'SignupDate' is in datetime format\n",
    "merged_df['SignupDate'] = pd.to_datetime(merged_df['SignupDate'])\n",
    "\n",
    "# Calculate days since joining\n",
    "merged_df['DaysSinceJoining'] = (pd.to_datetime('today') - merged_df['SignupDate']).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   CustomerID        1000 non-null   object        \n",
      " 1   CustomerName      1000 non-null   object        \n",
      " 2   Region            1000 non-null   object        \n",
      " 3   SignupDate        1000 non-null   datetime64[ns]\n",
      " 4   TransactionID     1000 non-null   object        \n",
      " 5   ProductID         1000 non-null   object        \n",
      " 6   TransactionDate   1000 non-null   object        \n",
      " 7   Quantity          1000 non-null   int64         \n",
      " 8   TotalValue        1000 non-null   float64       \n",
      " 9   Price             1000 non-null   float64       \n",
      " 10  DaysSinceJoining  1000 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(6)\n",
      "memory usage: 86.1+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocessing\n",
    "features_df = merged_df[['CustomerID','Region','TotalValue','DaysSinceJoining']]\n",
    "\n",
    "# One-hot encode Region as it's categorical\n",
    "features_df = pd.get_dummies(features_df, columns=['Region','CustomerID'])\n",
    "\n",
    "# Standardizing the numerical features (Quantity, TotalValue, Price)\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of clusters: 2\n",
      "Best Davies-Bouldin Index: 0.7596059938446725\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_kmeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m results_df\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Step 4: Add cluster labels to the dataframe\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m features_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mbest_kmeans\u001b[49m\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Display the updated DataFrame with cluster labels\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(features_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_kmeans' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop through different numbers of clusters for GridSearch\n",
    "for n_clusters in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(scaled_features)\n",
    "\n",
    "    # Calculate Davies-Bouldin Index\n",
    "    db_index = davies_bouldin_score(scaled_features, kmeans.labels_)\n",
    "\n",
    "    # Store the results in the list\n",
    "    results.append({'n_clusters': n_clusters, 'davies_bouldin_index': db_index})\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Step 3: Output the best results\n",
    "best_db_index = results_df['davies_bouldin_index'].min()\n",
    "best_n_clusters = results_df.loc[results_df['davies_bouldin_index'] == best_db_index, 'n_clusters'].values[0]\n",
    "\n",
    "print(f\"Best number of clusters: {best_n_clusters}\")\n",
    "print(f\"Best Davies-Bouldin Index: {best_db_index}\")\n",
    "\n",
    "\n",
    "# Display the DataFrame of all results\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize a DataFrame to store results\n",
    "cluster_results = []\n",
    "\n",
    "# Step 2: Loop through different numbers of clusters for GridSearch\n",
    "best_db_index = float('inf')\n",
    "best_kmeans = None\n",
    "best_n_clusters = 0\n",
    "\n",
    "# Try different numbers of clusters (from 2 to 10)\n",
    "for n_clusters in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(scaled_features)\n",
    "\n",
    "    # Calculate Davies-Bouldin Index\n",
    "    db_index = davies_bouldin_score(scaled_features, kmeans.labels_)\n",
    "\n",
    "    # Store the result for each iteration\n",
    "    cluster_results.append({\n",
    "        'n_clusters': n_clusters,\n",
    "        'davies_bouldin_index': db_index\n",
    "    })\n",
    "\n",
    "    # Track the best DBI (lower is better)\n",
    "    if db_index < best_db_index:\n",
    "        best_db_index = db_index\n",
    "        best_kmeans = kmeans\n",
    "        best_n_clusters = n_clusters\n",
    "\n",
    "# Step 3: Convert results to a DataFrame for easier analysis\n",
    "cluster_results_df = pd.DataFrame(cluster_results)\n",
    "\n",
    "# Display the results of each trial\n",
    "cluster_results_df\n",
    "\n",
    "# Step 4: Add cluster labels to the dataframe\n",
    "features_df['Cluster'] = best_kmeans.labels_\n",
    "\n",
    "# Display the updated DataFrame with cluster labels\n",
    "cluster_results_df\n",
    "\n",
    "# Step 4: Add cluster labels to the dataframe\n",
    "features_df['Cluster'] = best_kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualization\n",
    "# Visualize clusters using a pair plot\n",
    "sns.pairplot(features_df, hue='Cluster', palette='Set1')\n",
    "plt.savefig('pairplot.png')\n",
    "plt.show()\n",
    "\n",
    "# Reduce dimensions to 3D for visualization\n",
    "pca = PCA(n_components=3)\n",
    "pca_components = pca.fit_transform(scaled_features)\n",
    "\n",
    "# 3D scatter plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pca_components[:, 0], pca_components[:, 1], pca_components[:, 2], c=best_kmeans.labels_, cmap='Set1')\n",
    "ax.set_xlabel('PCA1')\n",
    "ax.set_ylabel('PCA2')\n",
    "ax.set_zlabel('PCA3')\n",
    "plt.title('3D Cluster Visualization')\n",
    "plt.savefig('3D Cluster Visualization.png', dpi=300)  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
